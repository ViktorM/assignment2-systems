{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton kernel test passed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.jit\n",
    "def test_kernel(x_ptr, output_ptr, BLOCK_SIZE: tl.constexpr):\n",
    "    pid = tl.program_id(0)\n",
    "    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "    tl.store(output_ptr + offsets, tl.load(x_ptr + offsets))\n",
    "\n",
    "print(\"Triton kernel test passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(x, weight):\n",
    "    # Here, assume that x has n-dim shape [..., D], and weight has 1D shape [D]\n",
    "    return (weight * x).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def weighted_sum_fwd(\n",
    "    x_ptr, weight_ptr, # Input pointers\n",
    "    output_ptr, # Output pointer\n",
    "    x_stride_row, x_stride_dim, # Strides tell us how to move one element in each axis of a tensor\n",
    "    weight_stride_dim, # Likely 1\n",
    "    output_stride_row, # Likely 1\n",
    "    NUM_ROWS, D,\n",
    "    ROWS_TILE_SIZE: tl.constexpr, D_TILE_SIZE: tl.constexpr, # Tile shapes must be known at compile time\n",
    "    ):\n",
    "    # Each instance will compute the weighted sum of a tile of rows of x.\n",
    "    # `tl.program_id` gives us a way to check which thread block we're running in\n",
    "    row_tile_idx = tl.program_id(0)\n",
    "\n",
    "    # Block pointers give us a way to select from an ND region of memory\n",
    "    # and move our selection around.\n",
    "    # The block pointer must know:\n",
    "    # - The pointer to the first element of the tensor\n",
    "    # - The overall shape of the tensor to handle out-of-bounds access\n",
    "    # - The strides of each dimension to use the memory layout properly\n",
    "    # - The ND coordinates of the starting block, i.e., \"offsets\"\n",
    "    # - The block shape to use load/store at a time\n",
    "    # - The order of the dimensions in memory from major to minor\n",
    "    #   axes (= np.argsort(strides)) for optimizations, especially useful on H100\n",
    "\n",
    "    x_block_ptr = tl.make_block_ptr(\n",
    "        x_ptr,\n",
    "        shape=(NUM_ROWS, D,),\n",
    "        strides=(x_stride_row, x_stride_dim),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE, 0),\n",
    "        block_shape=(ROWS_TILE_SIZE, D_TILE_SIZE),\n",
    "        order=(1, 0),\n",
    "        )\n",
    "\n",
    "    weight_block_ptr = tl.make_block_ptr(\n",
    "        weight_ptr,\n",
    "        shape=(D,),\n",
    "        strides=(weight_stride_dim,),\n",
    "        offsets=(0,),\n",
    "        block_shape=(D_TILE_SIZE,),\n",
    "        order=(0,),\n",
    "        )\n",
    "\n",
    "    output_block_ptr = tl.make_block_ptr(\n",
    "        output_ptr,\n",
    "        shape=(NUM_ROWS,),\n",
    "        strides=(output_stride_row,),\n",
    "        offsets=(row_tile_idx * ROWS_TILE_SIZE,),\n",
    "        block_shape=(ROWS_TILE_SIZE,),\n",
    "        order=(0,),\n",
    "        )\n",
    "\n",
    "    # Initialize a buffer to write to\n",
    "    output = tl.zeros((ROWS_TILE_SIZE,), dtype=tl.float32)\n",
    "\n",
    "    for i in range(tl.cdiv(D, D_TILE_SIZE)):\n",
    "        # Load the current block pointer\n",
    "        # Since ROWS_TILE_SIZE might not divide ROWS, and D_TILE_SIZE might not divide D,\n",
    "        # we need boundary checks for both dimensions\n",
    "        row = tl.load(x_block_ptr, boundary_check=(0, 1), padding_option=\"zero\") # (ROWS_TILE_SIZE, D_TILE_SIZE)\n",
    "        weight = tl.load(weight_block_ptr, boundary_check=(0,), padding_option=\"zero\") # (D_TILE_SIZE,)\n",
    "\n",
    "        # Compute the weighted sum of the row.\n",
    "        output += tl.sum(row * weight[None, :], axis=1)\n",
    "\n",
    "        # Move the pointers to the next tile.\n",
    "        # These are (rows, columns) coordinate deltas\n",
    "        x_block_ptr = x_block_ptr.advance((0, D_TILE_SIZE)) # Move by D_TILE_SIZE in the last dimension\n",
    "        weight_block_ptr = weight_block_ptr.advance((D_TILE_SIZE,)) # Move by D_TILE_SIZE\n",
    "\n",
    "    # Write output to the output block pointer (a single scalar per row).\n",
    "    # Since ROWS_TILE_SIZE might not divide ROWS, we need boundary checks\n",
    "    tl.store(output_block_ptr, output, boundary_check=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def weighted_sum_backward(\n",
    "    x_ptr, weight_ptr,  # Input\n",
    "    grad_output_ptr,    # Grad input\n",
    "    grad_x_ptr, partial_grad_weight_ptr,  # Grad outputs\n",
    "    stride_xr, stride_xd,\n",
    "    stride_wd,\n",
    "    stride_gr,\n",
    "    stride_gxr, stride_gxd,\n",
    "    stride_gwb, stride_gwd,\n",
    "    NUM_ROWS, D,\n",
    "    ROWS_TILE_SIZE: tl.constexpr, D_TILE_SIZE: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(0)\n",
    "    row_offsets = pid * ROWS_TILE_SIZE + tl.arange(0, ROWS_TILE_SIZE)\n",
    "    dim_offsets = tl.arange(0, D_TILE_SIZE)\n",
    "\n",
    "    grad_weight_local = tl.zeros((D_TILE_SIZE,), dtype=tl.float32)\n",
    "\n",
    "    for col in range(0, tl.cdiv(D, D_TILE_SIZE)):\n",
    "        # Load x, weight, and grad_output\n",
    "        x_tile = tl.load(\n",
    "            x_ptr + row_offsets[:, None] * stride_xr + (col * D_TILE_SIZE + dim_offsets[None, :]) * stride_xd,\n",
    "            mask=(row_offsets[:, None] < NUM_ROWS) & (col * D_TILE_SIZE + dim_offsets[None, :] < D),\n",
    "            other=0.0\n",
    "        )\n",
    "        weight_tile = tl.load(\n",
    "            weight_ptr + (col * D_TILE_SIZE + dim_offsets) * stride_wd,\n",
    "            mask=(col * D_TILE_SIZE + dim_offsets < D),\n",
    "            other=0.0\n",
    "        )\n",
    "        grad_output_tile = tl.load(\n",
    "            grad_output_ptr + row_offsets * stride_gr,\n",
    "            mask=(row_offsets < NUM_ROWS),\n",
    "            other=0.0\n",
    "        )[:, None]\n",
    "\n",
    "        # Compute gradients\n",
    "        grad_x_tile = grad_output_tile * weight_tile[None, :]\n",
    "        grad_weight_local += tl.sum(x_tile * grad_output_tile, axis=0)\n",
    "\n",
    "        # Store grad_x\n",
    "        tl.store(\n",
    "            grad_x_ptr + row_offsets[:, None] * stride_gxr + (col * D_TILE_SIZE + dim_offsets[None, :]) * stride_gxd,\n",
    "            grad_x_tile,\n",
    "            mask=(row_offsets[:, None] < NUM_ROWS) & (col * D_TILE_SIZE + dim_offsets[None, :] < D)\n",
    "        )\n",
    "\n",
    "    # Store partial gradients\n",
    "    tl.store(\n",
    "        partial_grad_weight_ptr + pid * stride_gwb + dim_offsets * stride_gwd,\n",
    "        grad_weight_local,\n",
    "        mask=(dim_offsets < D_TILE_SIZE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def weighted_sum_backward_optimized(\n",
    "    x_ptr, weight_ptr, grad_out_ptr,\n",
    "    grad_x_ptr, partial_grad_weight_ptr,\n",
    "    x_stride_row, x_stride_dim,\n",
    "    weight_stride_dim,\n",
    "    grad_out_stride_row,\n",
    "    grad_x_stride_row, grad_x_stride_dim,\n",
    "    partial_grad_weight_stride_row, partial_grad_weight_stride_dim,\n",
    "    NUM_ROWS, D,\n",
    "    ROWS_TILE_SIZE: tl.constexpr, D_TILE_SIZE: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(0)\n",
    "    row_start = pid * ROWS_TILE_SIZE\n",
    "    row_offsets = row_start + tl.arange(0, ROWS_TILE_SIZE)\n",
    "    dim_offsets = tl.arange(0, D_TILE_SIZE)\n",
    "\n",
    "    # Local gradient accumulator (very fast)\n",
    "    grad_weight_local = tl.zeros((D_TILE_SIZE,), dtype=tl.float32)\n",
    "\n",
    "    for col in range(0, tl.cdiv(D, D_TILE_SIZE)):\n",
    "        # Explicitly load tiles (fast shared loads)\n",
    "        x_tile = tl.load(\n",
    "            x_ptr + row_offsets[:, None] * x_stride_row + (col * D_TILE_SIZE + dim_offsets[None, :]) * x_stride_dim,\n",
    "            mask=(row_offsets[:, None] < NUM_ROWS) & (col * D_TILE_SIZE + dim_offsets[None, :] < D),\n",
    "            other=0.0\n",
    "        )\n",
    "\n",
    "        weight_tile = tl.load(\n",
    "            weight_ptr + col * D_TILE_SIZE + dim_offsets,\n",
    "            mask=(col * D_TILE_SIZE + dim_offsets < D),\n",
    "            other=0.0\n",
    "        )\n",
    "\n",
    "        grad_out_tile = tl.load(\n",
    "            grad_out_ptr + row_offsets * grad_out_stride_row,\n",
    "            mask=(row_offsets < NUM_ROWS),\n",
    "            other=0.0\n",
    "        )[:, None]\n",
    "\n",
    "        # Compute and store grad_x (once per tile explicitly)\n",
    "        grad_x_tile = grad_out_tile * weight_tile[None, :]\n",
    "        tl.store(\n",
    "            grad_x_ptr + row_offsets[:, None] * grad_x_stride_row + (col * D_TILE_SIZE + dim_offsets[None, :]) * grad_x_stride_dim,\n",
    "            grad_x_tile,\n",
    "            mask=(row_offsets[:, None] < NUM_ROWS) & (col * D_TILE_SIZE + dim_offsets[None, :] < D)\n",
    "        )\n",
    "\n",
    "        grad_weight_local += tl.sum(x_tile * grad_out_tile, axis=0)\n",
    "\n",
    "    # Store only one small partial gradient per block\n",
    "    tl.store(\n",
    "        partial_grad_weight_ptr + pid * partial_grad_weight_stride_row + tl.arange(0, D_TILE_SIZE),\n",
    "        grad_weight_local,\n",
    "        mask=(tl.arange(0, D_TILE_SIZE) < D)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def weighted_sum_backward_fully_optimized(\n",
    "    x_ptr, weight_ptr, grad_out_ptr,\n",
    "    grad_x_ptr, grad_weight_ptr,\n",
    "    x_stride_row, x_stride_dim,\n",
    "    weight_stride_dim,\n",
    "    grad_out_stride_row,\n",
    "    grad_x_stride_row, grad_x_stride_dim,\n",
    "    NUM_ROWS, D,\n",
    "    ROWS_TILE_SIZE: tl.constexpr, D_TILE_SIZE: tl.constexpr\n",
    "):\n",
    "    pid = tl.program_id(0)\n",
    "    row_offsets = pid * ROWS_TILE_SIZE + tl.arange(0, ROWS_TILE_SIZE)\n",
    "\n",
    "    # Loop over column tiles explicitly (unavoidable explicitly due to Triton constraints)\n",
    "    for col in range(0, tl.cdiv(D, D_TILE_SIZE)):\n",
    "        dim_offsets = col * D_TILE_SIZE + tl.arange(0, D_TILE_SIZE)\n",
    "\n",
    "        mask = (row_offsets[:, None] < NUM_ROWS) & (dim_offsets[None, :] < D)\n",
    "\n",
    "        # Load explicitly once per tile\n",
    "        x_tile = tl.load(\n",
    "            x_ptr + row_offsets[:, None] * x_stride_row + dim_offsets[None, :] * x_stride_dim,\n",
    "            mask=mask, other=0.0\n",
    "        )\n",
    "\n",
    "        grad_out_tile = tl.load(\n",
    "            grad_out_ptr + row_offsets * grad_out_stride_row,\n",
    "            mask=(row_offsets < NUM_ROWS), other=0.0\n",
    "        )[:, None]\n",
    "\n",
    "        weight_tile = tl.load(\n",
    "            weight_ptr + dim_offsets,\n",
    "            mask=(dim_offsets < D), other=0.0\n",
    "        )\n",
    "\n",
    "        # local buffer explicitly constrained by Triton (D_TILE_SIZE explicitly)\n",
    "        grad_weight_local = tl.sum(x_tile * grad_out_tile, axis=0)\n",
    "\n",
    "        # Explicit atomic-add per tile explicitly unavoidable given Triton constraints explicitly!\n",
    "        tl.atomic_add(\n",
    "            grad_weight_ptr + dim_offsets,\n",
    "            grad_weight_local,\n",
    "            mask=(dim_offsets < D)\n",
    "        )\n",
    "\n",
    "        # Efficient grad_x computation explicitly\n",
    "        grad_x_tile = weight_tile[None, :] * grad_out_tile\n",
    "\n",
    "        tl.store(\n",
    "            grad_x_ptr + row_offsets[:, None] * grad_x_stride_row + dim_offsets[None, :] * grad_x_stride_dim,\n",
    "            grad_x_tile,\n",
    "            mask=mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "\n",
    "class WeightedSumFunc(torch.autograd.Function):\n",
    "\n",
    "    ROWS_TILE_SIZE = 16\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x, weight):\n",
    "        D, output_dims = x.shape[-1], x.shape[:-1]\n",
    "        input_shape = x.shape\n",
    "        x = rearrange(x, \"... d -> (...) d\")\n",
    "\n",
    "        ctx.save_for_backward(x, weight)\n",
    "        assert x.is_cuda and weight.is_cuda, \"CUDA tensors required\"\n",
    "        assert x.is_contiguous(), \"Tensor x must be contiguous\"\n",
    "\n",
    "        n_rows = x.shape[0]\n",
    "\n",
    "        # Important fix: explicitly setting attributes on ctx\n",
    "        ctx.ROWS_TILE_SIZE = WeightedSumFunc.ROWS_TILE_SIZE\n",
    "        ctx.D_TILE_SIZE = triton.next_power_of_2(D) // ctx.ROWS_TILE_SIZE\n",
    "        #ctx.D_TILE_SIZE = min(D, max(16, triton.next_power_of_2(D) // ctx.ROWS_TILE_SIZE))\n",
    "\n",
    "        ctx.input_shape = input_shape\n",
    "\n",
    "        y = torch.empty((n_rows,), device=x.device)\n",
    "\n",
    "        # Define the grid explicitly\n",
    "        grid = (triton.cdiv(n_rows, ctx.ROWS_TILE_SIZE),)\n",
    "\n",
    "        weighted_sum_fwd[grid](\n",
    "            x, weight, y,\n",
    "            x.stride(0), x.stride(1),\n",
    "            weight.stride(0),\n",
    "            y.stride(0),\n",
    "            NUM_ROWS=n_rows, D=D,\n",
    "            ROWS_TILE_SIZE=ctx.ROWS_TILE_SIZE, D_TILE_SIZE=ctx.D_TILE_SIZE,\n",
    "        )\n",
    "\n",
    "        return y.view(output_dims)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        x, weight = ctx.saved_tensors\n",
    "        n_rows, D = x.shape\n",
    "\n",
    "        # Prepare explicitly smaller partial gradient buffer\n",
    "        grid = (triton.cdiv(n_rows, ctx.ROWS_TILE_SIZE),)\n",
    "        grad_weight = torch.zeros(D, device=x.device)\n",
    "        grad_x = torch.empty_like(x)\n",
    "        \n",
    "        use_fully_optimized = False\n",
    "        if use_fully_optimized:\n",
    "            # Call optimized Triton backward explicitly\n",
    "            weighted_sum_backward_fully_optimized[grid](\n",
    "                x, weight, grad_out,\n",
    "                grad_x, grad_weight,\n",
    "                x.stride(0), x.stride(1),\n",
    "                weight.stride(0),\n",
    "                grad_out.stride(0),\n",
    "                grad_x.stride(0), grad_x.stride(1),\n",
    "                NUM_ROWS=n_rows, D=D,\n",
    "                ROWS_TILE_SIZE=ctx.ROWS_TILE_SIZE, D_TILE_SIZE=ctx.D_TILE_SIZE,\n",
    "            )\n",
    "        else:\n",
    "            partial_grad_weight = torch.zeros((grid[0], D), device=x.device, dtype=x.dtype)\n",
    "\n",
    "            weighted_sum_backward[grid](\n",
    "                x, weight, grad_out,\n",
    "                grad_x, partial_grad_weight,\n",
    "                x.stride(0), x.stride(1),\n",
    "                weight.stride(0),\n",
    "                grad_out.stride(0),\n",
    "                grad_x.stride(0), grad_x.stride(1),\n",
    "                partial_grad_weight.stride(0), partial_grad_weight.stride(1),\n",
    "                n_rows, D,\n",
    "                ROWS_TILE_SIZE=ctx.ROWS_TILE_SIZE,\n",
    "                D_TILE_SIZE=D  # explicitly simple, whole dimension tile\n",
    "            )\n",
    "\n",
    "            grad_weight = partial_grad_weight.sum(dim=0)\n",
    "\n",
    "        return grad_x.view(ctx.input_shape), grad_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient x correct? True\n",
      "Gradient weight correct? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "torch.manual_seed(42)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Set dimensions (medium-scale explicitly recommended first)\n",
    "B, T, D = 256, 1024, 512\n",
    "\n",
    "# Initialize input explicitly\n",
    "x = torch.randn(B, T, D, device='cuda', requires_grad=True)\n",
    "weight = torch.randn(D, device='cuda', requires_grad=True)\n",
    "\n",
    "# Triton implementation (forward and backward explicitly)\n",
    "y_triton = WeightedSumFunc.apply(x, weight)\n",
    "loss_triton = y_triton.sum()\n",
    "loss_triton.backward()\n",
    "\n",
    "# Save gradients explicitly\n",
    "grad_x_triton = x.grad.clone()\n",
    "grad_weight_triton = weight.grad.clone()\n",
    "\n",
    "# Reset gradients explicitly for PyTorch verification\n",
    "x.grad.zero_()\n",
    "weight.grad.zero_()\n",
    "\n",
    "# PyTorch reference explicitly\n",
    "y_torch = (x * weight).sum(dim=-1)\n",
    "loss_torch = y_torch.sum()\n",
    "loss_torch.backward()\n",
    "\n",
    "# Explicitly verify correctness using torch.allclose\n",
    "grad_x_correct = torch.allclose(grad_x_triton, x.grad, atol=1e-4, rtol=1e-4)\n",
    "grad_weight_correct = torch.allclose(grad_weight_triton, weight.grad, atol=1e-4, rtol=1e-4)\n",
    "\n",
    "print(f\"Gradient x correct? {grad_x_correct}\")\n",
    "print(f\"Gradient weight correct? {grad_weight_correct}\")\n",
    "\n",
    "if not grad_x_correct:\n",
    "    print(\"Max difference in grad_x:\", (grad_x_triton - x.grad).abs().max())\n",
    "\n",
    "if not grad_weight_correct:\n",
    "    print(\"Max difference in grad_weight:\", (grad_weight_triton - weight.grad).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Benchmark results for Input Size: B=128, T=512, D=256\n",
      "================================================================================\n",
      "Tile Size  | Triton Time (ms)   | PyTorch Time (ms)  | Speedup (Torch/Triton)\n",
      "--------------------------------------------------------------------------------\n",
      "16         | 1.226              | 1.621              | 1.32                \n",
      "32         | 1.325              | 1.586              | 1.20                \n",
      "64         | 1.275              | 1.513              | 1.19                \n",
      "128        | 2.309              | 1.393              | 0.60                \n",
      "256        | 1.896              | 1.660              | 0.88                \n",
      "\n",
      "================================================================================\n",
      "Benchmark results for Input Size: B=256, T=1024, D=512\n",
      "================================================================================\n",
      "Tile Size  | Triton Time (ms)   | PyTorch Time (ms)  | Speedup (Torch/Triton)\n",
      "--------------------------------------------------------------------------------\n",
      "16         | 7.173              | 10.780             | 1.50                \n",
      "32         | 7.076              | 10.815             | 1.53                \n",
      "64         | 15.555             | 10.573             | 0.68                \n",
      "128        | 13.763             | 10.500             | 0.76                \n",
      "256        | 14.402             | 10.316             | 0.72                \n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import os\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Inputs explicitly\n",
    "# input_sizes = [[128, 512, 256], [256, 1024, 512], [256, 1024, 1024], [512, 2048, 512]]\n",
    "input_sizes = [[128, 512, 256], [256, 1024, 512]]\n",
    "tile_sizes = [16, 32, 64, 128, 256]\n",
    "\n",
    "for [B, T, D] in input_sizes:\n",
    "\n",
    "    # Initialize inputs explicitly\n",
    "    x = torch.randn(B, T, D, device='cuda', requires_grad=True)\n",
    "    weight = torch.randn(D, device='cuda', requires_grad=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for tile_size in tile_sizes:\n",
    "        WeightedSumFunc.ROWS_TILE_SIZE = tile_size\n",
    "\n",
    "        # Warm-up explicitly\n",
    "        WeightedSumFunc.apply(x, weight).sum().backward()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # Benchmark timing explicitly\n",
    "        triton_time = timeit.timeit(\n",
    "            lambda: (WeightedSumFunc.apply(x, weight).sum().backward(), torch.cuda.synchronize()),\n",
    "            number=100\n",
    "        )\n",
    "\n",
    "        torch_time = timeit.timeit(\n",
    "            lambda: ((x * weight).sum(dim=-1).sum().backward(), torch.cuda.synchronize()),\n",
    "            number=100\n",
    "        )\n",
    "\n",
    "        avg_triton = triton_time / 100 * 1000\n",
    "        avg_torch = torch_time / 100 * 1000\n",
    "        ratio = avg_torch / avg_triton\n",
    "\n",
    "        results.append((tile_size, avg_triton, avg_torch, ratio))\n",
    "\n",
    "    # Explicitly show input dimensions at top of each table\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Benchmark results for Input Size: B={B}, T={T}, D={D}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Tile Size':<10} | {'Triton Time (ms)':<18} | {'PyTorch Time (ms)':<18} | {'Speedup (Torch/Triton)':<20}\")\n",
    "    print(\"-\" * 80)\n",
    "    for ts, triton_t, torch_t, r in results:\n",
    "        print(f\"{ts:<10} | {triton_t:<18.3f} | {torch_t:<18.3f} | {r:<20.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROWS_TILE_SIZE 16\n",
    "Triton implementation avg time: 0.344 ms\n",
    "PyTorch native avg time: 0.189 ms\n",
    "\n",
    "# ROWS_TILE_SIZE 32\n",
    "Triton implementation avg time: 0.178 ms\n",
    "PyTorch native avg time: 0.063 ms\n",
    "\n",
    "# ROWS_TILE_SIZE 64\n",
    "Triton implementation avg time: 0.167 ms\n",
    "PyTorch native avg time: 0.078 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 4090 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
